<!DOCTYPE html>
<html lang="en">
<head>
  <title>Bahman Mirheidari</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</head>
<body>

<div class="container col-lg-10">
  <div class="container col-lg-6">  
    <!-- Nav tabs -->
    <ul class="nav nav-tabs" role="tablist">
      <li class="nav-item">
        <a class="nav-link active font-weight-bolder" data-toggle="tab" href="#home"><h5>Home</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#research"><h5>Research</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#publications"><h5>Publications</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#contact"><h5>Contact</h5></a>
      </li>
    </ul>  
  </div>  

  <!-- Main container -->
  <div class="container-fluid">     
    <div class="row">
      <!-- left part -->  
      <div class="col-lg-3"> 
        <img src="images/BahmanMirheidari.png" class="rounded-circle" alt="Bahman Mirheidari" width="140px" height="150px">  
        <table class="table-sm table-borderless">
          <thead>
            <tr>
              <th><div class="font-weight-bolder">Bahman Mirheidari</div></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Research Associate</td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter"><a href="https://www.sheffield.ac.uk/dcs/research/groups/spandh">Speech and Hearing Research Group (SpandH)</a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter"><a href="https://www.sheffield.ac.uk/dcs">Department of Computer Science</a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter"><a href="https://www.sheffield.ac.uk">University of Sheffield</a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-bold"><a href="https://scholar.google.com/citations?user=YSEWTLsAAAAJ&hl=en&oi=ao"><img src="images/googlescholar.png" class="rounded" alt="google scholar" height="25"></a></div> </td>
            </tr> 
            <tr>
              <td><div class="font-weight-bold"><a href="https://www.linkedin.com/in/bahman-mirheidari-89579a107/"><img src="images/linkedin.png" class="rounded" alt="linkedin" height="20"></a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-bold"><a href="https://orcid.org/0000-0002-7797-2778"><img src="images/orcid.png" class="rounded" alt="orcid" height="15"></a></div> </td>
            </tr>
            <tr> 
              <td><div class="font-weight-bold"><a href="https://www.researchgate.net/profile/Bahman_Mirheidari"><img src="images/researchgate.png" class="rounded" alt="researchgate" height="25"></a></div> </td>
            </tr>   
            
          </tbody>
        </table>   
      </div>  

      <!-- right part -->
      <div class="col-lg-6"> 
        <!-- Tab panes -->
        <div class="tab-content">
          <div id="home" class="container tab-pane active"><br>  
            <p> I am a Post Doc Research Associate (PDRA) at Department of Computer Science (<a href="https://www.sheffield.ac.uk/dcs">DCS</a>), University of Sheffield, and a member of the Speech and Hearing (<a href="https://www.sheffield.ac.uk/dcs/research/groups/spandh">SpandH</a>) group, and I am working with <a href="https://heidi-christensen.github.io/website">Dr Heidi Christensen</a>, who was also my PhD supervisor.</p>
            <p> My research interests include medial applications of Automatic Speech Recognition (ASR) (e.g. people with dementia, stroke, and/or other mental disorders), automatic analysis of conversation, speaker diarisation, and tracking speech and language changes over time.</p>
          </div>
          <div id="research" class="container tab-pane fade"><br>
            <h2>Research:</h2>
            <h4>COMPutational Assessment of Stroke Survivors Prototype funded by <a href="https://rosetreestrust.co.uk/interdisciplinary-award-applications/">Rosetrees Trust</a>, <a href="https://www.sheffield.ac.uk/pre/collaborate"> TUoS Knowledge Exchange</a>, and <a href="https://www.nihr.ac.uk/explore-nihr/support/clinical-research-network.htm">NIHR Clinical Research Network</a> (2020-2023)</h4>
            <p> 
              Aim: Stroke affects 152,000 UK citizens every year. Over 50% of stroke survivors have cognitive impairment. Currently, 850,000 people live with dementia in the UK and stroke is one of the biggest risk factors. However, current pen-and-paper based tests are not always appropriate for stroke survivors who often have motor, visual or language difficulties. In addition, longitudinal follow-up is required to detect emerging cognitive impairment.  Finally, assessments typically take place in hospital settings, are costly and often inconvenient for patients. This project aims to create an easy-to-use cognitive assessment tool specifically designed for the needs of stroke survivors. It will be based on our stratification tool COCOA (COmputational COgnitive Assessment), developed for detecting early signs of dementia. The tool uses automatic analysis of conversations that patients have with an on-screen digital doctor. 

            </p>

            <h4>COMPutational Assessment of Stroke Survivors Prototype (COMPASS-proto) funded by <a href="http://www.fast-healthcare.org.uk/">Fast Healthcare Networks Plus</a> (2019-2020)</h4>
            <p> 
              This project aims to create an easy-to-use cognitive assessment tool specifically designed for the needs of stroke survivors. It will be based on our stratification tool COCOA (COmputational COgnitive Assessment), developed for detecting early signs of dementia. The tool uses automatic analysis of conversations that patients have with an on-screen digital doctor. The patients’ speech is analysed for signs of cognitive decline using speech technology. This project will adapt our digital doctor’s questions to target vascular cognitive impairment, especially executive dysfunction, neglect and dysphasia. We will create an online version to enable home-based testing. <a href="http://www.fast-healthcare.org.uk/compass-proto/">read more ...</a>

            </p>

            <!-- <h3>Collaboration in Rolls Royce IIKE project (2019-2020)</h3>
            <p> The overall aim of the project is based on feasibility of developing ASR based interface for entering serial numbers to computer in an industial environment. </p>
            -->

            <h4>Collaboration in AvaChat project (2018-2019)</h4>
            <p>
              The study aimed to co-design the content, functionality, and interface modalities of an autonomous virtual agent to support self-management for patients with an exemplar long-term condition (LTC; chronic pulmonary obstructive disease [COPD]) and then to assess the acceptability and system content. <a href="https://www.jmir.org/2019/5/e12996">read more ...</a>
            </p>


            <h2>PhD:</h2>
            <h4>Detecting early signs of dementia in conversation (2015-2018) </h4>
            <p> 
              In this study we introduced an automatic approach for processing conversation between patients and neurologists which can help in identifying the early signs of dementia and distinguishing them from the other clinical categories (Functional Memory Disorder(FMD), Mild Cognitive Impairment (MCI), and Healthy Control (HC)). The dementia detection system starts with a speaker diarisation module to segment an input audio file (determining who talks when). Then the segmented files are passed to an automatic speech recogniser (ASR) to transcribe the utterances of each speaker. Next, the feature extraction unit extracts a number of features (Conversation Analysis-inspired, acoustic, lexical and word vector) from the transcripts and audio files. Finally, a classifier is trained by the features to determine the clinical category of the input conversation. Moreover, we investigated replacing the role of a neurologist in the conversation with an Intelligent Virtual Agent (IVA) (asking similar questions), and we showed that despite differences between the IVA-led and the neurologist-led conversations, the results achieved by the IVA were as good as those gained by the neurologists. <a href="http://etheses.whiterose.ac.uk/23607/1/PhD_Thesis_Final.pdf">read more ...</a>  
            </p>   
            
          </div>
          <div id="publications" class="container tab-pane fade"><br>
            <h2>Publications:</h2>

            <h3>Journal papers</h3>
              <ul>
                <li> Walker, G., Morris, L. A., Christensen, H., Mirheidari, B., Reuber, M., & Blackburn, D. J. (2020). Characterising spoken responses to an intelligent virtual agent by persons with mild cognitive impairment. Clinical linguistics & phonetics, 1-16. <a href="bib/walker2020characterising.bib">bib</a> <a href="https://www.tandfonline.com/doi/pdf/10.1080/02699206.2020.1777586">link</a>
                </li>
                <li> O’Malley, R., Morris, L. A., Longden, C., Turner, A., Walker, T., Venneri, A., ... & Blackburn, D. (2020). 26 Can an automated assessment of language help distinguish between Functional Cognitive Disorder and early neurodegeneration?. <a href="bib/omalley2020.bib">bib</a> <a href="https://jnnp.bmj.com/content/jnnp/91/8/e18.2.full.pdf">link</a>
                </li>
                <li> O’Malley, R., Mirheidari, B., Harkness, K., Walker, T., Reuber, M., Venneri, A., ... & Blackburn, D. (2020). A fully automated cognitive screening tool based on assessment of speech and language (5548). <a href="bib/omalley2020fully.bib">bib</a> <a href="https://n.neurology.org/content/94/15_Supplement/5548.abstract">link</a>
                </li>
                <li> Walker, T., Christensen, H., Mirheidari, B., Swainston, T., Rutten, C., Mayer, I., ... & Reuber, M. (2020). Developing an intelligent virtual agent to stratify people with cognitive complaints: A comparison of human–patient and intelligent virtual agent–patient interaction. Dementia, 19(4), 1173-1188. <a href="bib/walker2020developing.bib">bib</a> <a href="https://journals.sagepub.com/doi/pdf/10.1177/1471301218795238">link</a>
                </li> 
                <li> Mirheidari, B., Blackburn, D., Walker, T., Reuber, M., & Christensen, H. (2019). Dementia detection using automatic analysis of conversations. Computer Speech & Language, 53, 65-79. <a href="bib/mirheidari2019dementia.bib">bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0885230817303583">link</a>
                </li>
                <li> Easton, K., Potter, S., Bec, R., Bennion, M., Christensen, H., Grindell, C., ... & Hawley, M. S. (2019). A virtual agent to support individuals living with physical and mental comorbidities: co-design and acceptability testing. Journal of medical Internet research, 21(5), e12996. <a href="bib/easton2019virtual.bib">bib</a> <a href="https://www.jmir.org/2019/5/e12996">link</a>
                </li>
                <li> Easton, K., Potter, S., Bec, R., Bennion, M., Christensen, H., Grindell, C., ... & Hawley, M. (2019). Co-designing and testing the acceptability of a virtual agent to support self-management for individuals living with physical and mental comorbidities. Journal of Medical Internet Research. <a href="bib/easton2019co.bib">bib</a> <a href="http://eprints.whiterose.ac.uk/144308/8/A%20Virtual%20Agent%20to%20Support%20Individuals%20Living%20With%20Physical.pdf">link</a>
                </li>  
                <li> Al-Hameed, S., Benaissa, M., Christensen, H., Mirheidari, B., Blackburn, D., & Reuber, M. (2019). A new diagnostic approach for the identification of patients with neurodegenerative cognitive complaints. PloS one, 14(5), e0217388. <a href="bib/al2019new.bib">bib</a> <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0217388">link</a>
                </li>
                <li> Walker, T., Christensen, H., Mirheidari, B., Swainston, T., Rutten, C., Mayer, I., ... & Reuber, M. (2018). Developing an Intelligent Virtual Agent (IVA) to stratify people with cognitive complaints: a comparison of human-patient and IVA-patient interaction. <a href="bib/walker2018developing.bib">bib</a> <a href="https://core.ac.uk/download/pdf/199217676.pdf">link</a>
                </li>
                <li> Mirheidari, B., Blackburn, D., Harkness, K., Walker, T., Venneri, A., Reuber, M., & Christensen, H. (2017). Toward the automation of diagnostic conversation analysis in patients with memory complaints. Journal of Alzheimer's Disease, 58(2), 373-387. <a href="bib/mirheidari2017toward.bib">bib</a> <a href="https://content.iospress.com/articles/journal-of-alzheimers-disease/jad160507">link</a>
                </li>   
                <li> Blackburn, D., Mirheidari, B. M., Rutten, C., Mayer, I., Walker, T., Christensen, H., & Rueber, M. (2017). PO029 An avatar aid in memory clinic. <a href="bib/blackburn2017po029.bib">bib</a> <a href="https://jnnp.bmj.com/content/jnnp/88/Suppl_1/A19.4.full.pdf">link</a>
                </li>
                <li> Blackburn, D., Reuber, M., Christensen, H., Mayer, I., Rutten, C., Venneri, A., & Mirheidari, B. (2017). An avatar to screen for cognitive impairment. Journal of the Neurological Sciences, 381, 319. <a href="bib/blackburn2017avatar.bib">bib</a> <a href="https://www.jns-journal.com/article/S0022-510X(17)31401-6/abstract">link</a>
                </li>  
              </ul>

            <h3>Conference papers</h3>
              <ul>  
                <li> *Mirheidari, B., Blackburn, D., O'Malley, R., Venneri, A., Walker, T., Reuber, M., & Christensen, H. (2020). Improving cognitive impairment classification by generative neural network-based feature augmentation. Interspeech 2020.  
                </li> 
                <li> *Pan, Y., Mirheidari, B., Tu, Z., O'Malley, R., Walker, T., Venneri, A., Reuber, M., Blackburn, D., & Christensen, H. (2020). Acoustic feature extraction with interpretable deep neural network for neurodegenerative related disorder classification. Interspeech 2020.  
                </li> 
                <li> *Pan, Y., Mirheidari, B., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2020). Improving detection of Alzheimer’s Disease using automatic speech recognition to identify high-quality segments for more robust feature extraction. Interspeech 2020.  
                </li>


                <li> Pan, Y., Mirheidari, B., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2019). Automatic Hierarchical Attention Neural Network for Detecting AD. In Interspeech (pp. 4105-4109). <a href="bib/pan2019automatic.bib">bib</a> <a href="https://pdfs.semanticscholar.org/365f/ab1146a72ad08799db52a07ef2a45038315e.pdf">link</a>
                </li>

                <li> Mirheidari, B., Blackburn, D., O’Malley, R., Walker, T., Venneri, A., Reuber, M., & Christensen, H. (2019, May). Computational cognitive assessment: Investigating the use of an intelligent virtual agent for the detection of early signs of dementia. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2732-2736). IEEE. <a href="bib/mirheidari2019computational.bib">bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8682423">link</a>
                </li>

                <li> Mirheidari, B., Blackburn, D., Walker, T., Venneri, A., Reuber, M., & Christensen, H. (2018). Detecting Signs of Dementia Using Word Vector Representations. In INTERSPEECH (pp. 1893-1897). <a href="bib/mirheidari2018detecting.bib">bib</a> <a href="https://www.researchgate.net/profile/Markus_Reuber/publication/327389414_Detecting_Signs_of_Dementia_Using_Word_Vector_Representations/links/5bf7ecfaa6fdcc5388152f61/Detecting-Signs-of-Dementia-Using-Word-Vector-Representations.pdf">link</a>
                </li>

                <li> Mirheidari, B., Blackburn, D. J., Harkness, K., Walker, T., Venneri, A., Reuber, M., & Christensen, H. (2017, July). An avatar-based system for identifying individuals likely to develop dementia. In Interspeech 2017 (pp. 3147-3151). ISCA. <a href="bib/mirheidari2017avatar.bib">bib</a> <a href="http://eprints.whiterose.ac.uk/126604/7/0690.PDF">link</a>
                </li> 

                <li> Mirheidari, B., Blackburn, D., Reuber, M., Walker, T., & Christensen, H. (2016, September). Diagnosing people with dementia using automatic conversation analysis. In Proceedings of interspeech (pp. 1220-1224). ISCA. <a href="bib/mirheidari2016diagnosing.bib">bib</a> <a href="http://eprints.whiterose.ac.uk/106798/1/Bahman_Interspeech_2016.pdf">link</a>
                </li> 

              </ul>
            <h3>Other papers</h3>
              <ul> 
                <li> Mirheidari, B., Pan, Y., Blackburn, D., O'Malley, R., Walker, T., Venneri, A., ... & Christensen, H. (2020). Data augmentation using generative networks to identify dementia. arXiv preprint arXiv:2004.05989. <a href="bib/mirheidari2020data.bib">bib</a> <a href="https://arxiv.org/pdf/2004.05989.pdf">link</a>
                </li>
                 
                <li> Mirheidari, B., Pan, Y., Walker, T., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2019). Detecting Alzheimer's Disease by estimating attention and elicitation path through the alignment of spoken picture descriptions with the picture prompt. arXiv preprint arXiv:1910.00515. <a href="bib/mirheidari2019detecting.bib">bib</a> <a href="https://arxiv.org/pdf/1910.00515.pdf">link</a>
                </li>

              </ul>

            <h3>PhD Thesis</h3> 
              <ul>
                <li> Mirheidari, B. (2018). Detecting early signs of dementia in conversation (Doctoral dissertation, University of Sheffield). <a href="bib/mirheidari2018thesis.bib">bib</a> <a href="http://etheses.whiterose.ac.uk/23607/1/PhD_Thesis_Final.pdf">link</a>
                </li>
              </ul>

          </div>

          <div id="contact" class="container tab-pane fade"><br>
            <h2>Contact details:</h2>
            
            <table class="table-sm table-borderless">
              <thead>
                <tr>
                  <th>Bahman Mirheidari</th>
                </tr>
              </thead>
              <tbody> 
                <tr>
                  <td><div class="font-weight-lighter">Department of Computer Science</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">University of Sheffield</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">Regent Court, 211 Portobello, Room 149</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">Sheffield, S1 4DP, UK</div> </td>
                </tr>
                <tr>
                  <td>Phone: +44 114 222 1918</td>
                </tr>
                <tr>
                  <td>Email: b.mirheidari@sheffield.ac.uk</td>
                </tr>
              </tbody>
            </table>   

          </div>

        </div>
      </div>
    </div>

  </div>
</div>

</body>
</html>
