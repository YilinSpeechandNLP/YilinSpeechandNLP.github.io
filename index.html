<!DOCTYPE html>
<html lang="en">
<head>
  <title>Yilin Pan</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
</head>
<body>

<div class="container col-lg-10">
  <div class="container col-lg-6">  
    <!-- Nav tabs -->
    <ul class="nav nav-tabs" role="tablist">
      <li class="nav-item">
        <a class="nav-link active font-weight-bolder" data-toggle="tab" href="#home"><h5>Home</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#education"><h5>Education</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#publications"><h5>Publications</h5></a>
      </li>
      <li class="nav-item">
        <a class="nav-link font-weight-bolder" data-toggle="tab" href="#contact"><h5>Contact</h5></a>
      </li>
      </li>
    </ul>  
  </div>  

  <!-- Main container -->
  <div class="container-fluid">     
    <div class="row">
      <!-- left part -->  
      <div class="col-lg-3"> 
        <img src="images/Yilin.jpg" class="rounded-circle" alt="Yilin Pan" width="140px" height="150px">  
        <table class="table-sm table-borderless">
          <thead>
            <tr>
              <th><div class="font-weight-bolder">Yilin Pan</div></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Lecturer</td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter">Speech and Language Research Group</div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter"><a href="https://ai.dlmu.edu.cn/#:~:text=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E9%99%A22022">College of Artificial Intelligence</a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-lighter"><a href="https://www.dlmu.edu.cn/">Dalian Maritime University</a></div> </td>
            </tr>
            <tr>
              <td><div class="font-weight-bold"><a href="https://scholar.google.com/citations?user=Yrzc2wgAAAAJ&hl=zh-CN"><img src="images/googlescholar.png" class="rounded" alt="google scholar" height="25"></a></div> </td>
            </tr> 
            <tr>
              <td><div class="font-weight-bold"><a href="https://www.linkedin.com/in/yilin-pan-268144194/"><img src="images/linkedin.png" class="rounded" alt="linkedin" height="20"></a></div> </td>
            </tr>
            <tr> 
              <td><div class="font-weight-bold"><a href="https://www.researchgate.net/profile/Yilin-Pan-5"><img src="images/researchgate.png" class="rounded" alt="researchgate" height="25"></a></div> </td>
            </tr>   
            
          </tbody>
        </table>   
      </div>  

      <!-- right part -->
      <div class="col-lg-6"> 
        <!-- Tab panes -->
        <div class="tab-content">
          <div id="home" class="container tab-pane active"><br>  
            <p> I am a lecturer at the College of Artificial Intelligence, Dalian Maritime University  (<a href="https://ai.dlmu.edu.cn/#:~:text=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E9%99%A22022">DCS</a>). </p>
             <p>  I got my PhD degree at Department of Computer Science (<a href="https://www.sheffield.ac.uk/dcs">DCS</a>), University of Sheffield, and was a member of the Speech and Hearing (<a href="https://www.sheffield.ac.uk/dcs/research/groups/spandh">SpandH</a>) group. I was supervised by <a href="https://heidi-christensen.github.io/website">Prof Heidi Christensen</a>.</p>
            <p> I was a Early Stage Researcher (ESR) on the European Union H2020 Training Network on Automatic Processing of Pathological Speech (<a href="https://www.tapas-etn-eu.org/">TAPAS</a>). My research project is <b>Using Speech Analysis to Detect Onset and Monitor Cognitive Decline </b> funded by <a href="https://cordis.europa.eu/project/id/766287">Training Network on Automatic Processing of PAthological Speech</a> (2018-2022).</p>
			<p> My research interests include speech based cognitive impairment (e.g. people with dementia, stroke, and/or other mental disorders) detection, speaker verification, speech processing and natural language processing. More detailed information can be found in my CV (<a href="CV/English_CV.pdf">English version</a>, <a href="CV/Chinese_CV.pdf">Chinese version</a>).</p>
          </div>
          <div id="education" class="container tab-pane fade"><br>
           <b>PhD:</b>
            <p>SpandH Research Group, Computer Science Department, the University of Sheffield, UK (2018-2022) </p> 

            <b>Master:</b>
            <p>SpLab Research Group, Computer Science Department, Harbin Institute Technology, China (2015-2017) </p> 

            <b>Bachelor:</b>
            <p>Computer Science Department, Northeastern University, China (2011-2015) </p>             
          </div>
		  
          <div id="publications" class="container tab-pane fade"><br>
            <h3>Conference papers</h3>
              <ul> 
			    <li>  <b>Pan, Y.*</b>,  Mirheidari, B.*, Harris, J. M., Thompson, J. C., Jones, M., Snowden, J. S., Blackburn, D., and Christensen, H. ( (2021). <b>Using the Outputs of Different Automatic Speech Recognition Paradigms for Acoustic-and BERT-Based Alzheimer’s Dementia Detection Through Spontaneous Speech</b>. Interspeech 2021. <a href="bib/pan2021using.bib">bib</a> <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/pan21c_interspeech.pdf">link</a>
                </li>
			    <li>  <b>Pan, Y.</b>,  Nallanthighal, V. S., Blackburn, D., Christensen, H., & Härmä, A. (2021). <b>Multi-Task Estimation of Age and Cognitive Decline from Speech</b>. In ICASSP (pp. 7258-7262). <a href="bib/pan2021multi.bib">bib</a> <a href="https://www.tapas-etn-eu.org/Members/yilin--pan/icassp_2021.pdf">link</a>
                </li>	
                <li> <b>Pan, Y.</b>, Mirheidari, B., Tu, Z., O'Malley, R., Walker, T., Venneri, A., Reuber, M., Blackburn, D., & Christensen, H. (2020). <b>Acoustic feature extraction with interpretable deep neural network for neurodegenerative related disorder classification</b>. Interspeech 2020. <a href="bib/pan2020acoustic.bib">bib</a> <a href="http://www.interspeech2020.org/uploadfile/pdf/Thu-3-6-6.pdf">link</a>
                </li>				
                </li> 
                <li> <b>Pan, Y.</b>, Mirheidari, B., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2020). <b>Improving detection of Alzheimer’s Disease using automatic speech recognition to identify high-quality segments for more robust feature extraction</b>. Interspeech 2020. <a href="bib/pan2020improving.bib">bib</a> <a href="https://pdfs.semanticscholar.org/41a1/33c6847e36aba44ebbf378e4780a19250031.pdf">link</a>
                </li>
				<li> Cummins, N., <b>Pan, Y.</b>, Ren, Z., Fritsch, J., Nallanthighal, V. S., Christensen, H., ... & Härmä, A. (2020, October). <b>A comparison of acoustic and linguistics methodologies for Alzheimer’s dementia recognition</b>. In Interspeech 2020 (pp. 2182-2186). <a href="bib/cummins2020comparison.bib">bib</a> <a href="https://eprints.whiterose.ac.uk/170037/7/A%20comparison%20of%20acoustic%20and%20linguistics%20methodologies%20for%20Alzheimer%E2%80%99s%20dementia%20recognition.pdf">link</a>
				</li>
                <li> <b>Pan, Y.</b>, Mirheidari, B., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2019). <b>Automatic Hierarchical Attention Neural Network for Detecting Alzheimer's Disease</b>. In Interspeech (pp. 4105-4109). <a href="bib/pan2019automatic.bib">bib</a> <a href="https://pdfs.semanticscholar.org/365f/ab1146a72ad08799db52a07ef2a45038315e.pdf">link</a>
                </li>	
				<li> Chen, C., Han, J., & <b>Pan, Y.</b> (2017). <b>Speaker Verification via Estimating Total Variability Space Using Probabilistic Partial Least Squares</b>. In INTERSPEECH (pp. 1537-1541). <a href="bib/chen2017speaker.bib">bib</a> <a href="https://www.researchgate.net/profile/Chen-Chen-223/publication/319185644_Speaker_Verification_via_Estimating_Total_Variability_Space_Using_Probabilistic_Partial_Least_Squares/links/5e76bd8692851cf2719da531/Speaker-Verification-via-Estimating-Total-Variability-Space-Using-Probabilistic-Partial-Least-Squares.pdf">link</a>
				</li>
				<li> <b>Pan, Y.</b>, Zheng, T., & Chen, C. (2017). <b>I-vector Kullback-Leibler divisive normalization for PLDA speaker verification</b>. In 2017 IEEE Global Conference on Signal and Information Processing (GlobalSIP) (pp. 56-60). <a href="bib/pan2017vector.bib">bib</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8308603&casa_token=ABrBtm1Vdd8AAAAA:JjRDWItRH_vHYJRnEmHQ4UOlgE6sxL6qa2_IgUVbUhgQcrMfryGxGs0vDx4rJj0-gACgD_F4q0I&tag=1">link</a>
				</li>

              </ul>
            <h3>Journal papers</h3>
              <ul>
                <li> <b>Pan, Y.</b>,  Shi, Y., Zhang,  Y., &  Lu, M., (2023). <b>A path signature approach for speech-based dementia detection</b>. In IEEE Signal Processing Letters. <a href="bib/mirheidari2020data.bib">bib</a> <a href="https://ieeexplore.ieee.org/abstract/document/10171424/">link</a>
                </li>

              </ul>
            <h3>Other papers</h3>
              <ul> 
                <li> Mirheidari, B., <b>Pan, Y.</b>, Blackburn, D., O'Malley, R., Walker, T., Venneri, A., ... & Christensen, H. (2020). <b>Data augmentation using generative networks to identify dementia</b>. arXiv preprint arXiv:2004.05989. <a href="bib/mirheidari2020data.bib">bib</a> <a href="https://arxiv.org/pdf/2004.05989.pdf">link</a>
                </li>
                 
                <li> Mirheidari, B., <b>Pan, Y.</b>, Walker, T., Reuber, M., Venneri, A., Blackburn, D., & Christensen, H. (2019). <b>Detecting Alzheimer's Disease by estimating attention and elicitation path through the alignment of spoken picture descriptions with the picture prompt</b>. arXiv preprint arXiv:1910.00515. <a href="bib/mirheidari2019detecting.bib">bib</a> <a href="https://arxiv.org/pdf/1910.00515.pdf">link</a>
                </li>

              </ul>


          </div>

          <div id="contact" class="container tab-pane fade"><br>
            <h2>Contact details:</h2>
            
            <table class="table-sm table-borderless">
              <thead>
                <tr>
                  <th>Yilin Pan</th>
                </tr>
              </thead>
              <tbody> 
			    <td>Email: yilin.pan@dlmu.edu.cn</td>
                <tr>
                <td><div class="font-weight-lighter">College of Artificial Intelligence</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">Dalian Maritine University</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">MinXue Building, No.1 Lingshui Road, Room 407</div> </td>
                </tr>
                <tr>
                  <td><div class="font-weight-lighter">Dalian, Liaoning Province, China</div> </td>
                </tr>
                <tr>
                  
                </tr>
              </tbody>
            </table>   

          </div>

        </div>
      </div>
    </div>

  </div>
</div>

</body>
</html>
